<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>How to Run and Upload dbProfile Results</title>
<style type="text/css">
/**
 * Prism.s theme ported from highlight.js's xcode style
 */
pre code {
  padding: 1em;
}
.token.comment {
  color: #007400;
}
.token.punctuation {
  color: #999;
}
.token.tag,
.token.selector {
  color: #aa0d91;
}
.token.boolean,
.token.number,
.token.constant,
.token.symbol {
  color: #1c00cf;
}
.token.property,
.token.attr-name,
.token.string,
.token.char,
.token.builtin {
  color: #c41a16;
}
.token.inserted {
  background-color: #ccffd8;
}
.token.deleted {
  background-color: #ffebe9;
}
.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
  color: #9a6e3a;
}
.token.atrule,
.token.attr-value,
.token.keyword {
  color: #836c28;
}
.token.function,
.token.class-name {
  color: #DD4A68;
}
.token.regex,
.token.important,
.token.variable {
  color: #5c2699;
}
.token.important,
.token.bold {
  font-weight: bold;
}
.token.italic {
  font-style: italic;
}
</style>
<style type="text/css">
body {
  font-family: sans-serif;
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 1.5;
  box-sizing: border-box;
}
body, .footnotes, code { font-size: .9em; }
li li { font-size: .95em; }
*, *:before, *:after {
  box-sizing: inherit;
}
pre, img { max-width: 100%; }
pre, pre:hover {
  white-space: pre-wrap;
  word-break: break-all;
}
pre code {
  display: block;
  overflow-x: auto;
}
code { font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace; }
:not(pre) > code, code[class] { background-color: #F8F8F8; }
code.language-undefined, pre > code:not([class]) {
  background-color: inherit;
  border: 1px solid #eee;
}
table {
  margin: auto;
  border-top: 1px solid #666;
}
table thead th { border-bottom: 1px solid #ddd; }
th, td { padding: 5px; }
thead, tfoot, tr:nth-child(even) { background: #eee; }
blockquote {
  color: #666;
  margin: 0;
  padding-left: 1em;
  border-left: 0.5em solid #eee;
}
hr, .footnotes::before { border: 1px dashed #ddd; }
.frontmatter { text-align: center; }
#TOC .numbered li { list-style: none; }
#TOC .numbered { padding-left: 0; }
#TOC .numbered ul { padding-left: 1em; }
table, .body h2 { border-bottom: 1px solid #666; }
.body .appendix, .appendix ~ h2 { border-bottom-style: dashed; }
.footnote-ref a::before { content: "["; }
.footnote-ref a::after { content: "]"; }
section.footnotes::before {
  content: "";
  display: block;
  max-width: 20em;
}

@media print {
  body {
    font-size: 12pt;
    max-width: 100%;
  }
  tr, img { page-break-inside: avoid; }
}
@media only screen and (min-width: 992px) {
  pre { white-space: pre; }
}
</style>
</head>
<body>
<div class="include-before">
</div>
<div class="frontmatter">
<div class="title"><h1>How to Run and Upload dbProfile Results</h1></div>
<div class="author"><h2></h2></div>
<div class="date"><h3>2024-07-22</h3></div>
</div>
<div class="body">
<p>This document will take you through the steps on how to run the database profile functions and upload them to a location to be reference when running database diagnostics.</p>
<h2 id="set-the-parameters-to-run-executedbprofile">Set the parameters to run executeDbProfile</h2>
<p>Call the <code>createConnectionDetails</code> function to create the object, inputting the information for how to connect to your database. Detailed instructions on how to do this can be found <a href="http://ohdsi.github.io/DatabaseConnector/articles/Connecting.html">here</a>.</p>
<pre><code class="language-r">##### --------- Install the package

remotes::install_github(&quot;OHDSI/DbDiagnostics&quot;)

# Call the library
library(DbDiagnostics)

# Turn off the connection pane to speed up run time
options(connectionObserver = NULL)

# Set up connectionDetails to connect to the database
connectionDetails &lt;- DatabaseConnector::createConnectionDetails(
	dbms = &quot;postgresql&quot;,
	server = &quot;localhost/synthea&quot;,
	user = &quot;postgres&quot;,
	password = Sys.getenv(&quot;POSTGRES_PW&quot;),
	pathToDriver = &quot;/Users/clairblacketer/Documents/DatabaseConnector_Jars&quot;
)

# The schema where your CDM-structured data are housed
cdmDatabaseSchema &lt;- &quot;cdm_54_test&quot;

# The schema where your achilles results are or will be housed
resultsDatabaseSchema &lt;- &quot;cdm_54_results&quot;

# The schema where your vocabulary tables are housed, typically the same as the cdmDatabaseSchema
vocabDatabaseSchema &lt;- cdmDatabaseSchema

# A unique, identifiable name for your database
cdmSourceName &lt;- &quot;Synthea_v54_OHDSI_Example&quot;

# The folder where your results should be written
outputFolder &lt;- &quot;/Users/clairblacketer/Documents/Output/DbProfiles&quot;

# The version of the OMOP CDM you are currently on, v5.3 and v5.4 are supported.
cdmVersion &lt;- &quot;5.4&quot;

# Whether the function should append existing Achilles tables or create new ones
appendAchilles &lt;- FALSE

# The schema where any missing achilles analyses should be written. Only set if appendAchilles = FALSE
writeTo &lt;- &quot;synthea_achilles&quot;

# Whether to round to the 10s or 100s place. Valid inputs are 10 or 100, default is 10.
roundTo &lt;- 10

# Vector of concepts to exclude from the output. Note: No patient-level data is pulled as part of the package or included as part of the output
excludedConcepts &lt;- c()

# Whether the DQD should be run as part of the profile exercise
addDQD &lt;- FALSE
  
</code></pre>
<h2 id="run-the-executedbprofile-function">Run the executeDbProfile function</h2>
<pre><code class="language-r">
DbDiagnostics::executeDbProfile(connectionDetails = connectionDetails,
																cdmDatabaseSchema = cdmDatabaseSchema,
																resultsDatabaseSchema = resultsDatabaseSchema,
																writeTo = writeTo,
																vocabDatabaseSchema = vocabDatabaseSchema,
																cdmSourceName = cdmSourceName,
																outputFolder = outputFolder,
																cdmVersion = cdmVersion,
																appendAchilles = appendAchilles,
																roundTo = roundTo,
																excludedConcepts = excludedConcepts,
																addDQD = addDQD
																)

</code></pre>
<p>Upon completion, the summary statistics results <code>*.csv</code> file, the CDM_SOURCE table, metadata.csv and the data quality dashboard JSON file (if specified) will be located in a zip file in the output location you set as part of the execute function.</p>
<h2 id="upload-dbprofile-results-to-a-local-schema">Upload dbProfile results to a local schema</h2>
<p>Be sure to unzip the dbProfile results that are generated in the above. Then, set the location where you unzipped the results as the parameter <code>resultsLocation</code>. Any parameter below denoted as <cdmSourceName> should be replaced with the database key that was generated when <code>executeDbProfile</code> was run. You can find this in the file names.</p>
<pre><code class="language-r">
# set the location of the results that were generated from executeDbProfile
resultsLocation &lt;- &quot;&quot;

# set a parameter detailing if the DQD was run
addDQD &lt;- FALSE

# add dbId and prep output files for writing into the results schema
db_profile_results &lt;- read.csv(paste0(resultsLocation,&quot;/db_profile_results.csv&quot;), stringsAsFactors = F, colClasses = c(&quot;STRATUM_1&quot;=&quot;character&quot;))

# make sure the columns are read in as characters to facilitate dbDiagnostics execution
db_profile_results$STRATUM_1 &lt;- as.character(db_profile_results$STRATUM_1)
db_profile_results$STRATUM_2 &lt;- as.character(db_profile_results$STRATUM_2)
db_profile_results$STRATUM_3 &lt;- as.character(db_profile_results$STRATUM_3)
db_profile_results$STRATUM_4 &lt;- as.character(db_profile_results$STRATUM_4)
db_profile_results$STRATUM_5 &lt;- as.character(db_profile_results$STRATUM_5)

# read in the metadata

db_metadata &lt;- read.csv(paste0(resultsLocation,&quot;/&lt;cdmSourceName&gt;_metadata.csv&quot;), stringsAsFactors = F)

# read in the cdm_source table

db_cdm_source &lt;- read.csv(paste0(resultsLocation,&quot;/&lt;cdmSourceName&gt;_cdm_source.csv&quot;), stringsAsFactors = F)

# determine which tables should be uploaded based on if the DQD was included
if (addDQD) {

	dqdJsonDf &lt;- jsonlite::fromJSON(
		paste0(outputFolder,&quot;/&quot;,dbId,&quot;_DbProfile.json&quot;),
		simplifyDataFrame = TRUE)

	dqd_overview     &lt;- as.data.frame(dqdJsonDf$Overview)
	dqd_checkresults &lt;- as.data.frame(dqdJsonDf$CheckResults)
	
	dqd_checkresults$THRESHOLD_VALUE &lt;- as.character(dqd_checkresults$THRESHOLD_VALUE)

	tablesToUpload &lt;- c(&quot;db_profile_results&quot;,&quot;db_metadata&quot;,&quot;db_cdm_source&quot;,&quot;dqd_checkresults&quot;,&quot;dqd_overview&quot;)
} else {
	tablesToUpload &lt;- c(&quot;db_profile_results&quot;,&quot;db_metadata&quot;,&quot;db_cdm_source&quot;)
}

# create the connectionDetails for the database where the results should be uploaded. It is likely this will be different than the database where the dbProfile was run

connectionDetails &lt;- DatabaseConnector::createConnectionDetails(
	dbms = &quot;postgresql&quot;,
	server = &quot;localhost/synthea&quot;,
	user = &quot;postgres&quot;,
	password = Sys.getenv(&quot;POSTGRES_PW&quot;)
)

conn &lt;- DatabaseConnector::connect(connectionDetails)

# When the schema is empty, use createTable = TRUE
for (tableName in tablesToUpload) {
	DatabaseConnector::insertTable(
		connection        = conn,
		tableName         = tableName,
		databaseSchema    = &quot;cdm_54_results&quot;,
		data              = eval(parse(text=tableName)),
		dropTableIfExists = FALSE,
		createTable       = TRUE,
		tempTable         = FALSE,
		progressBar       = TRUE)
}

DatabaseConnector::disconnect(conn)
</code></pre>
</div>
<div class="include-after">
</div>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js" defer></script>
</body>
</html>
